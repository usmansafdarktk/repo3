{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8702411,"sourceType":"datasetVersion","datasetId":5219463},{"sourceId":8703033,"sourceType":"datasetVersion","datasetId":5219923},{"sourceId":8703300,"sourceType":"datasetVersion","datasetId":5220120}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.preprocessing import LabelEncoder\nimport glob\nimport os\nimport re\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-10T07:31:32.612076Z","iopub.execute_input":"2024-08-10T07:31:32.612545Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"2024-08-10 07:31:37.575233: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-10 07:31:37.575353: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-10 07:31:37.738132: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Data Loading**","metadata":{}},{"cell_type":"code","source":"# For train data\nfolder_path = '/kaggle/input/attacks/csv/train'\ncsv_files = glob.glob(os.path.join(folder_path, '*.csv'))\ndataframes = []\nsampling_fraction = 3000_00 / 7_000_000\nlst = ['Benign','MQTT-DDoS-Connect_Flood','Recon-Port_Scan','MQTT-DoS-Publish_Flood','MQTT-DDoS-Publish_Flood','Recon-OS_Scan','ARP_Spoofing','MQTT-DoS-Connect_Flood','MQTT-Malformed_Data','Recon-VulScan','Recon-Ping_Sweep']\nfor file in csv_files:\n    df = pd.read_csv(file, skiprows=lambda i: i>0 and np.random.random() > sampling_fraction)\n    attack_category = os.path.basename(file)[:-15] # Ensure correct slicing based on file name format\n    if attack_category not in lst:\n        attack_category = attack_category[:-1]\n    df['Attack_Category'] = attack_category\n    dataframes.append(df)\nmerged_data = pd.concat(dataframes, ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-23T11:35:13.260531Z","iopub.execute_input":"2024-06-23T11:35:13.261600Z","iopub.status.idle":"2024-06-23T11:35:48.488743Z","shell.execute_reply.started":"2024-06-23T11:35:13.261565Z","shell.execute_reply":"2024-06-23T11:35:48.487868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Shape of the combined DataFrame (train):\", merged_data.shape)\nprint(merged_data['Attack_Category'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2024-06-23T11:35:50.694158Z","iopub.execute_input":"2024-06-23T11:35:50.694911Z","iopub.status.idle":"2024-06-23T11:35:50.755026Z","shell.execute_reply.started":"2024-06-23T11:35:50.694875Z","shell.execute_reply":"2024-06-23T11:35:50.754068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"folder_path = '/kaggle/input/attacks/csv/test'\ncsv_files = glob.glob(os.path.join(folder_path, '*.csv'))\ndataframes = []\nsampling_fraction = 200000 / 1_600_000\nlst = ['TCP_IP-DDoS-UDP1','TCP_IP-DDoS-UDP2','TCP_IP-DDoS-UDP2','TCP_IP-DDoS-ICMP1','TCP_IP-DDoS-ICMP2']\nfor file in csv_files:\n    df = pd.read_csv(file, skiprows=lambda i: i>0 and np.random.random() > sampling_fraction)\n    attack_category = os.path.basename(file)[:-14] # Ensure correct slicing based on file name format\n    if attack_category in lst:\n        attack_category = attack_category[:-1]\n    df['Attack_Category'] = attack_category\n    dataframes.append(df)\n\ntest_data = pd.concat(dataframes, ignore_index=True)\nprint(\"Shape of the combined DataFrame:\", test_data.shape)\nprint(test_data['Attack_Category'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2024-06-23T11:35:54.847978Z","iopub.execute_input":"2024-06-23T11:35:54.848391Z","iopub.status.idle":"2024-06-23T11:36:03.485211Z","shell.execute_reply.started":"2024-06-23T11:35:54.848357Z","shell.execute_reply":"2024-06-23T11:36:03.484215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 8))\nax = sns.countplot(x='Attack_Category', data=merged_data, palette='viridis')\nplt.title('Distribution of Different Types of Cyber Attacks', fontsize=16)\nplt.xlabel('Attack Category', fontsize=14)\nplt.ylabel('Frequency', fontsize=14)\nplt.xticks(rotation=45)\nplt.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scatter plot with bubble size\nplt.figure(figsize=(12, 8))\nbubble_size = merged_data['Weight'] / merged_data['Weight'].max() * 1000  # Normalizing the 'Weight' for bubble size\nscatter = plt.scatter('Duration', 'Rate', s=bubble_size, alpha=0.5, data=merged_data, c='Drate', cmap='spring')\nplt.legend(*scatter.legend_elements(\"sizes\", num=6), title='Weight')\nplt.colorbar(scatter)\nplt.title('Duration vs Rate Colored by Drate with Weight Indication', fontsize=16)\nplt.xlabel('Duration', fontsize=14)\nplt.ylabel('Rate', fontsize=14)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **EDA**","metadata":{}},{"cell_type":"code","source":"merged_data.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_data = merged_data.sample(n=10000, random_state=1)  # Random state for reproducibility\nplt.figure(figsize=(10, 6))\nsns.scatterplot(data=sample_data, x='Duration', y='Rate', color= 'red')\nplt.title('Scatter Plot of Duration vs Rate')\nplt.xlabel('Duration')\nplt.ylabel('Rate')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 8))\nsns.boxplot(x='Attack_Category', y='Duration', data=merged_data)\nplt.xticks(rotation=45)\nplt.title('Box Plot of Duration by Attack Category')\nplt.xlabel('Attack Category')\nplt.ylabel('Duration')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.pairplot(sample_data[['Duration', 'Rate', 'Srate', 'Drate']], diag_kind='kde')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Pre-Processing**","metadata":{}},{"cell_type":"code","source":"print(f\"Total Duplicate Values are : {sum(merged_data.duplicated())}\")\nprint(f\"Total Null Values are : {sum(merged_data.isnull().sum())}\")\nmerged_data.drop_duplicates(inplace=True)\nprint(f\"Total Duplicate Values are : {sum(merged_data.duplicated())}\")\n\nprint(f\"Total Duplicate Values in Testing Data are : {sum(test_data.duplicated())}\")\nprint(f\"Total Null Values in Testing Data are : {sum(test_data.isnull().sum())}\")\ntest_data.drop_duplicates(inplace=True)\nprint(f\"Total Duplicate Values are : {sum(test_data.duplicated())}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-23T11:36:11.115621Z","iopub.execute_input":"2024-06-23T11:36:11.116104Z","iopub.status.idle":"2024-06-23T11:36:13.360924Z","shell.execute_reply.started":"2024-06-23T11:36:11.116074Z","shell.execute_reply":"2024-06-23T11:36:13.359895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def detect_outliers(data, feature):\n    Q1 = data[feature].quantile(0.25)\n    Q3 = data[feature].quantile(0.75)\n    IQR = Q3 - Q1\n    lower_bound = Q1 - 1.5 * IQR\n    upper_bound = Q3 + 1.5 * IQR\n    outliers = data[(data[feature] < lower_bound) | (data[feature] > upper_bound)]\n    return outliers\n\noutliers_duration = detect_outliers(merged_data, 'Duration')\nprint(f\"Number of outliers in Duration: {outliers_duration.shape[0]}\")\nprint(\"Shape of data before removing outliers:\", merged_data.shape)\nmerged_data = merged_data[~merged_data.index.isin(outliers_duration.index)]\nprint(\"Shape of data after removing outliers:\", merged_data.shape)","metadata":{"execution":{"iopub.status.busy":"2024-06-23T11:36:16.642442Z","iopub.execute_input":"2024-06-23T11:36:16.642842Z","iopub.status.idle":"2024-06-23T11:36:16.726437Z","shell.execute_reply.started":"2024-06-23T11:36:16.642812Z","shell.execute_reply":"2024-06-23T11:36:16.725406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Encoding**","metadata":{}},{"cell_type":"code","source":"X_train = merged_data.drop('Attack_Category', axis=1)\ny_train = merged_data['Attack_Category']\nX_test = test_data.drop('Attack_Category', axis=1)\ny_test = test_data['Attack_Category']","metadata":{"execution":{"iopub.status.busy":"2024-06-23T11:36:20.068182Z","iopub.execute_input":"2024-06-23T11:36:20.068927Z","iopub.status.idle":"2024-06-23T11:36:20.129198Z","shell.execute_reply.started":"2024-06-23T11:36:20.068894Z","shell.execute_reply":"2024-06-23T11:36:20.128351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = StandardScaler()\nfeatures_to_scale = merged_data.columns.difference(['Attack_Category'])\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\nlabel_encoder = LabelEncoder()\ny_train = label_encoder.fit_transform(y_train)\ny_test = label_encoder.transform(y_test)","metadata":{"execution":{"iopub.status.busy":"2024-06-23T11:36:22.816968Z","iopub.execute_input":"2024-06-23T11:36:22.817334Z","iopub.status.idle":"2024-06-23T11:36:23.135000Z","shell.execute_reply.started":"2024-06-23T11:36:22.817307Z","shell.execute_reply":"2024-06-23T11:36:23.134205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Correlation Analysis**","metadata":{}},{"cell_type":"code","source":"correlation_matrix = merged_data.select_dtypes(include=[np.number]).corr()\ncorrelation_matrix","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extract the upper triangle of the correlation matrix\nupper_triangle = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(np.bool_))\n\n# Find the top N correlated features\ntop_correlated_features = upper_triangle.unstack().abs().sort_values(ascending=False).dropna().head(10)\n\n# Collect unique features from the top correlations\nunique_features = set()\nfor index in top_correlated_features.index:\n    unique_features.add(index[0])\n    unique_features.add(index[1])\nunique_features = list(unique_features)\n\n# Plot the heatmap of the top N correlated features\nplt.figure(figsize=(10, 6))  # Adjust the size accordingly\nsns.heatmap(correlation_matrix.loc[unique_features, unique_features], annot=True, cmap='coolwarm', fmt='.2f', linewidths=.5)\nplt.xticks(rotation=45, ha='right')\nplt.yticks(rotation=0)\nplt.title('Top 10 Correlated Features in Dataset')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Modelling**","metadata":{}},{"cell_type":"markdown","source":"## **Logistic Regression**","metadata":{}},{"cell_type":"code","source":"logistic_model = LogisticRegression(max_iter=100)\nlogistic_model.fit(X_train, y_train)\ny_pred_logistic = logistic_model.predict(X_test)\nacc_logistic = accuracy_score(y_test, y_pred_logistic)\nprint(\"Logistic Regression Accuracy:\", acc_logistic)\nprint(classification_report(y_test, y_pred_logistic))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Example metrics for each model\nmetrics_logistic = {'Accuracy': 0.85, 'Precision': 0.84, 'Recall': 0.83, 'F1-Score': 0.84}\nmetrics_decision_tree = {'Accuracy': 0.80, 'Precision': 0.79, 'Recall': 0.78, 'F1-Score': 0.79}\nmetrics_random_forest = {'Accuracy': 0.88, 'Precision': 0.89, 'Recall': 0.87, 'F1-Score': 0.88}\nmetrics_ann = {'Accuracy': 0.90, 'Precision': 0.91, 'Recall': 0.89, 'F1-Score': 0.90}\nimport pandas as pd\n\n# Create a DataFrame\ndata = {\n    'Model': ['Logistic Regression', 'Decision Tree', 'Random Forest', 'ANN'],\n    'Accuracy': [metrics_logistic['Accuracy'], metrics_decision_tree['Accuracy'], \n                 metrics_random_forest['Accuracy'], metrics_ann['Accuracy']],\n    'Precision': [metrics_logistic['Precision'], metrics_decision_tree['Precision'], \n                  metrics_random_forest['Precision'], metrics_ann['Precision']],\n    'Recall': [metrics_logistic['Recall'], metrics_decision_tree['Recall'], \n               metrics_random_forest['Recall'], metrics_ann['Recall']],\n    'F1-Score': [metrics_logistic['F1-Score'], metrics_decision_tree['F1-Score'], \n                 metrics_random_forest['F1-Score'], metrics_ann['F1-Score']]\n}\ndf = pd.DataFrame(data)\ndf_melted = df.melt(id_vars=[\"Model\"], var_name=\"Metric\", value_name=\"Value\")\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Set the aesthetic style of the plots\nsns.set(style=\"whitegrid\")\n\n# Initialize the matplotlib figure\nplt.figure(figsize=(12, 8))\n\n# Create a bar plot\nax = sns.barplot(x='Metric', y='Value', hue='Model', data=df_melted, palette='viridis')\n\n# Add the data labels on top of the bars\nfor p in ax.patches:\n    ax.annotate(format(p.get_height(), '.2f'), \n                (p.get_x() + p.get_width() / 2., p.get_height()), \n                ha = 'center', va = 'center', \n                xytext = (0, 9), \n                textcoords = 'offset points')\n\n# Final touches\nplt.title('Comparison of Machine Learning Models Across Multiple Metrics', fontsize=16)\nplt.xlabel('Metric', fontsize=14)\nplt.ylabel('Value', fontsize=14)\nplt.legend(title='Model')\n\n# Show plot\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Decision Tree**","metadata":{}},{"cell_type":"code","source":"dt_model = DecisionTreeClassifier()\ndt_model.fit(X_train, y_train)\ny_pred_dt = dt_model.predict(X_test)\nacc_dt = accuracy_score(y_test, y_pred_dt)\nprint(\"Decision Tree Accuracy:\", acc_dt)\nprint(classification_report(y_test, y_pred_dt, target_names=label_encoder.classes_))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Random Forest**","metadata":{}},{"cell_type":"code","source":"rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\nrf_model.fit(X_train, y_train)\ny_pred_rf = rf_model.predict(X_test)\nacc_rf = accuracy_score(y_test, y_pred_rf)\nprint(\"Random Forest Accuracy:\", acc_rf)\nprint(classification_report(y_test, y_pred_rf, target_names=label_encoder.classes_))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **ANN Architecture**","metadata":{}},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense(units=128, activation='relu', input_shape=(X_train.shape[1],)))\nmodel.add(Dense(units=64, activation='relu'))\nmodel.add(Dense(units=32, activation='relu'))\nmodel.add(Dense(units=len(np.unique(y_train)), activation='softmax'))\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(X_train, y_train, epochs=10, batch_size=128, validation_split=0.2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_prob = model.predict(X_test)\ny_pred = np.argmax(y_pred_prob, axis=1)\n\nacc_ann = accuracy_score(y_test, y_pred)\nprint(\"ANN Accuracy:\", acc_ann)\nprint(classification_report(y_test, y_pred, target_names=label_encoder.classes_))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming you've trained the models and made predictions already as per your previous message\nreport_logistic = classification_report(y_test, y_pred_logistic, output_dict=True)\nreport_dt = classification_report(y_test, y_pred_dt, output_dict=True)\nreport_rf = classification_report(y_test, y_pred_rf, output_dict=True)\nreport_ann = classification_report(y_test, y_pred, output_dict=True)  # For ANN mode\n# Function to extract the average scores for the metrics\ndef extract_metrics(report):\n    return {\n        'Accuracy': report['accuracy'],\n        'Precision': report['weighted avg']['precision'],\n        'Recall': report['weighted avg']['recall'],\n        'F1-Score': report['weighted avg']['f1-score']\n    }\n\n# Get metrics\nmetrics_logistic = extract_metrics(report_logistic)\nmetrics_dt = extract_metrics(report_dt)\nmetrics_rf = extract_metrics(report_rf)\nmetrics_ann = extract_metrics(report_ann)\n\n# Create a DataFrame\ndata = {\n    'Model': ['Logistic Regression', 'Decision Tree', 'Random Forest', 'ANN'],\n    'Accuracy': [metrics_logistic['Accuracy'], metrics_dt['Accuracy'], metrics_rf['Accuracy'], metrics_ann['Accuracy']],\n    'Precision': [metrics_logistic['Precision'], metrics_dt['Precision'], metrics_rf['Precision'], metrics_ann['Precision']],\n    'Recall': [metrics_logistic['Recall'], metrics_dt['Recall'], metrics_rf['Recall'], metrics_ann['Recall']],\n    'F1-Score': [metrics_logistic['F1-Score'], metrics_dt['F1-Score'], metrics_rf['F1-Score'], metrics_ann['F1-Score']]\n}\ndf = pd.DataFrame(data)\ndf_melted = df.melt(id_vars=[\"Model\"], var_name=\"Metric\", value_name=\"Value\")\n# Set the aesthetic style of the plots\nsns.set(style=\"whitegrid\")\n\n# Initialize the matplotlib figure\nplt.figure(figsize=(12, 8))\n\n# Create a bar plot\nax = sns.barplot(x='Metric', y='Value', hue='Model', data=df_melted, palette='viridis')\n\n# Add data labels\nfor p in ax.patches:\n    ax.annotate(format(p.get_height(), '.2f'), \n                (p.get_x() + p.get_width() / 2., p.get_height()), \n                ha = 'center', va = 'center', \n                xytext = (0, 9), \n                textcoords = 'offset points')\n\n# Final touches\nplt.title('Comparison of Machine Learning Models Across Multiple Metrics', fontsize=16)\nplt.xlabel('Metric', fontsize=14)\nplt.ylabel('Value', fontsize=14)\nplt.legend(title='Model', loc='center right')\n\n# Show plot\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming rf_model is a trained RandomForestClassifier\nimportances = rf_model.feature_importances_\nfeature_names = merged_data.drop('Attack_Category', axis=1).columns\n\n# Create a DataFrame of features and their importance\nimportance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n\n# Sort the DataFrame by importance in descending order\nimportance_df = importance_df.sort_values(by='Importance', ascending=False)\n\n# Select the top 10 features\ntop_features = importance_df.head(10)\n# Set the aesthetic style of the plots\nsns.set(style=\"whitegrid\")\n\n# Initialize the matplotlib figure\nplt.figure(figsize=(10, 6))\n\n# Create a bar plot for the top 10 features\nsns.barplot(x='Importance', y='Feature', data=top_features, palette='viridis')\n\n# Add labels and title\nplt.title('Top 10 Feature Importances in Random Forest Model', fontsize=16)\nplt.xlabel('Importance', fontsize=14)\nplt.ylabel('Feature', fontsize=14)\n\n# Show plot\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import SimpleRNN, Dense\nfrom tensorflow.keras.utils import to_categorical\n\n# Convert labels to one-hot encoding\ny_train_onehot = to_categorical(y_train)\ny_test_onehot = to_categorical(y_test)\n\n# Reshape input data for RNN (samples, time steps, features)\nX_train_rnn = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\nX_test_rnn = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n\n# Build the RNN model\nrnn_model = Sequential([\n    SimpleRNN(64, input_shape=(1, X_train.shape[1]), activation='relu'),\n    Dense(32, activation='relu'),\n    Dense(y_train_onehot.shape[1], activation='softmax')\n])\n\nrnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Train the model\nrnn_history = rnn_model.fit(X_train_rnn, y_train_onehot, epochs=5, batch_size=32, validation_split=0.2, verbose=1)\n\n# Evaluate the model\ny_pred_rnn = rnn_model.predict(X_test_rnn)\ny_pred_rnn_classes = np.argmax(y_pred_rnn, axis=1)\nacc_rnn = accuracy_score(y_test, y_pred_rnn_classes)\nprint(\"RNN Accuracy:\", acc_rnn)\nprint(classification_report(y_test, y_pred_rnn_classes, target_names=label_encoder.classes_))","metadata":{"execution":{"iopub.status.busy":"2024-06-23T08:53:13.319584Z","iopub.execute_input":"2024-06-23T08:53:13.319965Z","iopub.status.idle":"2024-06-23T09:20:37.570872Z","shell.execute_reply.started":"2024-06-23T08:53:13.319936Z","shell.execute_reply":"2024-06-23T09:20:37.569857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import LSTM\n\n# Reshape input data for LSTM (samples, time steps, features)\nX_train_lstm = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\nX_test_lstm = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n\n# Build the LSTM model\nlstm_model = Sequential([\n    LSTM(64, input_shape=(1, X_train.shape[1]), activation='relu', return_sequences=True),\n    LSTM(32, activation='relu'),\n    Dense(16, activation='relu'),\n    Dense(y_train_onehot.shape[1], activation='softmax')\n])\n\nlstm_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Train the model\nlstm_history = lstm_model.fit(X_train_lstm, y_train_onehot, epochs=5, batch_size=32, validation_split=0.2, verbose=1)\n\n# Evaluate the model\ny_pred_lstm = lstm_model.predict(X_test_lstm)\ny_pred_lstm_classes = np.argmax(y_pred_lstm, axis=1)\nacc_lstm = accuracy_score(y_test, y_pred_lstm_classes)\nprint(\"LSTM Accuracy:\", acc_lstm)\nprint(classification_report(y_test, y_pred_lstm_classes, target_names=label_encoder.classes_))","metadata":{"execution":{"iopub.status.busy":"2024-06-23T09:20:42.672872Z","iopub.execute_input":"2024-06-23T09:20:42.673243Z","iopub.status.idle":"2024-06-23T09:51:04.162962Z","shell.execute_reply.started":"2024-06-23T09:20:42.673212Z","shell.execute_reply":"2024-06-23T09:51:04.161789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom sklearn.metrics import classification_report\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Assuming you've trained the models and made predictions already\nreport_rnn = classification_report(y_test, y_pred_rnn_classes, output_dict=True)\nreport_lstm = classification_report(y_test, y_pred_lstm_classes, output_dict=True)\n\n# Function to extract the average scores for the metrics\ndef extract_metrics(report):\n    return {\n        'Accuracy': report['accuracy'],\n        'Precision': report['weighted avg']['precision'],\n        'Recall': report['weighted avg']['recall'],\n        'F1-Score': report['weighted avg']['f1-score']\n    }\n\n# Get metrics\nmetrics_rnn = extract_metrics(report_rnn)\nmetrics_lstm = extract_metrics(report_lstm)\n\n# Create a DataFrame\ndata = {\n    'Model': ['RNN', 'LSTM'],\n    'Accuracy': [metrics_rnn['Accuracy'], metrics_lstm['Accuracy']],\n    'Precision': [metrics_rnn['Precision'], metrics_lstm['Precision']],\n    'Recall': [metrics_rnn['Recall'], metrics_lstm['Recall']],\n    'F1-Score': [metrics_rnn['F1-Score'], metrics_lstm['F1-Score']]\n}\n\ndf = pd.DataFrame(data)\ndf_melted = df.melt(id_vars=[\"Model\"], var_name=\"Metric\", value_name=\"Value\")\n\n# Set the aesthetic style of the plots\nsns.set(style=\"whitegrid\")\n\n# Initialize the matplotlib figure\nplt.figure(figsize=(12, 8))\n\n# Create a bar plot\nax = sns.barplot(x='Metric', y='Value', hue='Model', data=df_melted, palette='viridis')\n\n# Add data labels\nfor p in ax.patches:\n    ax.annotate(format(p.get_height(), '.4f'), \n                (p.get_x() + p.get_width() / 2., p.get_height()), \n                ha = 'center', va = 'center', \n                xytext = (0, 9), \n                textcoords = 'offset points',\n                fontsize=10)\n\n# Final touches\nplt.title('Comparison of Deep Learning Models, RNN and LSTM , Across Multiple Metrics', fontsize=16)\nplt.xlabel('Metric', fontsize=14)\nplt.ylabel('Value', fontsize=14)\nplt.legend(title='Model', loc='upper right')\n\n# Adjust layout to prevent cutting off labels\nplt.tight_layout()\n\n# Show plot\nplt.show()\n\n\n# from sklearn.metrics import classification_report\n# import pandas as pd\n# import seaborn as sns\n# import matplotlib.pyplot as plt\n\n# # Assuming you've trained the models and made predictions already\n# report_logistic = classification_report(y_test, y_pred_logistic, output_dict=True)\n# report_dt = classification_report(y_test, y_pred_dt, output_dict=True)\n# report_rf = classification_report(y_test, y_pred_rf, output_dict=True)\n# report_ann = classification_report(y_test, y_pred, output_dict=True)  # For ANN model\n# report_rnn = classification_report(y_test, y_pred_rnn_classes, output_dict=True)\n# report_lstm = classification_report(y_test, y_pred_lstm_classes, output_dict=True)\n\n# # Function to extract the average scores for the metrics\n# def extract_metrics(report):\n#     return {\n#         'Accuracy': report['accuracy'],\n#         'Precision': report['weighted avg']['precision'],\n#         'Recall': report['weighted avg']['recall'],\n#         'F1-Score': report['weighted avg']['f1-score']\n#     }\n\n# # Get metrics\n# metrics_logistic = extract_metrics(report_logistic)\n# metrics_dt = extract_metrics(report_dt)\n# metrics_rf = extract_metrics(report_rf)\n# metrics_ann = extract_metrics(report_ann)\n# metrics_rnn = extract_metrics(report_rnn)\n# metrics_lstm = extract_metrics(report_lstm)\n\n# # Create a DataFrame\n# data = {\n#     'Model': ['Logistic Regression', 'Decision Tree', 'Random Forest', 'ANN', 'RNN', 'LSTM'],\n#     'Accuracy': [metrics_logistic['Accuracy'], metrics_dt['Accuracy'], metrics_rf['Accuracy'], \n#                  metrics_ann['Accuracy'], metrics_rnn['Accuracy'], metrics_lstm['Accuracy']],\n#     'Precision': [metrics_logistic['Precision'], metrics_dt['Precision'], metrics_rf['Precision'], \n#                   metrics_ann['Precision'], metrics_rnn['Precision'], metrics_lstm['Precision']],\n#     'Recall': [metrics_logistic['Recall'], metrics_dt['Recall'], metrics_rf['Recall'], \n#                metrics_ann['Recall'], metrics_rnn['Recall'], metrics_lstm['Recall']],\n#     'F1-Score': [metrics_logistic['F1-Score'], metrics_dt['F1-Score'], metrics_rf['F1-Score'], \n#                  metrics_ann['F1-Score'], metrics_rnn['F1-Score'], metrics_lstm['F1-Score']]\n# }\n\n# df = pd.DataFrame(data)\n# df_melted = df.melt(id_vars=[\"Model\"], var_name=\"Metric\", value_name=\"Value\")\n\n# # Set the aesthetic style of the plots\n# sns.set(style=\"whitegrid\")\n\n# # Initialize the matplotlib figure\n# plt.figure(figsize=(15, 10))\n\n# # Create a bar plot\n# ax = sns.barplot(x='Metric', y='Value', hue='Model', data=df_melted, palette='viridis')\n\n# # Add data labels\n# for p in ax.patches:\n#     ax.annotate(format(p.get_height(), '.2f'), \n#                 (p.get_x() + p.get_width() / 2., p.get_height()), \n#                 ha = 'center', va = 'center', \n#                 xytext = (0, 9), \n#                 textcoords = 'offset points',\n#                 fontsize=8)\n\n# # Final touches\n# plt.title('Comparison of Machine Learning Models Across Multiple Metrics', fontsize=16)\n# plt.xlabel('Metric', fontsize=14)\n# plt.ylabel('Value', fontsize=14)\n# plt.legend(title='Model', loc='upper right', bbox_to_anchor=(1.25, 1))\n\n# # Adjust layout to prevent cutting off labels\n# plt.tight_layout()\n\n# # Show plot\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-23T09:51:12.679225Z","iopub.execute_input":"2024-06-23T09:51:12.679765Z","iopub.status.idle":"2024-06-23T09:51:15.606452Z","shell.execute_reply.started":"2024-06-23T09:51:12.679732Z","shell.execute_reply":"2024-06-23T09:51:15.605506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.decomposition import PCA\n\n# Elbow curve method\ninertias = []\nsilhouette_scores = []\nK = range(2, 11)  # We'll test from 2 to 10 clusters\n\nfor k in K:\n    kmeans = KMeans(n_clusters=k, random_state=42)\n    kmeans.fit(X_train)\n    inertias.append(kmeans.inertia_)\n    \n    # Silhouette score\n    labels = kmeans.labels_\n    silhouette_scores.append(silhouette_score(X_train, labels))\n\n# Plot the elbow curve\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.plot(K, inertias, 'bx-')\nplt.xlabel('k')\nplt.ylabel('Inertia')\nplt.title('Elbow Method for Optimal k')\n\n# Plot the silhouette scores\nplt.subplot(1, 2, 2)\nplt.plot(K, silhouette_scores, 'rx-')\nplt.xlabel('k')\nplt.ylabel('Silhouette Score')\nplt.title('Silhouette Score for Optimal k')\n\nplt.tight_layout()\nplt.show()\n\n# Choose the optimal k based on the elbow curve and silhouette scores\noptimal_k = 5  # You should adjust this based on the elbow curve and silhouette scores\n\n# Perform K-means clustering with the optimal k\nkmeans = KMeans(n_clusters=optimal_k, random_state=42)\nkmeans_labels = kmeans.fit_predict(X_train)\n\n# Evaluate the clustering\nsilhouette_avg = silhouette_score(X_train, kmeans_labels)\nprint(f\"The average silhouette score for K-means clustering with {optimal_k} clusters: {silhouette_avg}\")\n\n# Visualize the clustering (using first two principal components for 2D visualization)\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X_train)\n\nplt.figure(figsize=(10, 8))\nscatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=kmeans_labels, cmap='viridis')\nplt.title(f'K-means Clustering Visualization (k={optimal_k})')\nplt.colorbar(scatter)\nplt.show()\n# from sklearn.cluster import KMeans\n# from sklearn.metrics import silhouette_score\n# import matplotlib.pyplot as plt\n\n# # Assuming X_train is already scaled. If not, uncomment the following lines:\n# # from sklearn.preprocessing import StandardScaler\n# # scaler = StandardScaler()\n# # X_train_scaled = scaler.fit_transform(X_train)\n\n# # K-means clustering\n# n_clusters = 5  # You can adjust this based on your domain knowledge or using methods like elbow curve\n\n# kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n# kmeans_labels = kmeans.fit_predict(X_train)\n\n# # Evaluate the clustering\n# silhouette_avg = silhouette_score(X_train, kmeans_labels)\n# print(f\"The average silhouette score for K-means clustering: {silhouette_avg}\")\n\n# # Visualize the clustering (using first two principal components for 2D visualization)\n# from sklearn.decomposition import PCA\n\n# pca = PCA(n_components=2)\n# X_pca = pca.fit_transform(X_train)\n\n# plt.figure(figsize=(10, 8))\n# scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=kmeans_labels, cmap='viridis')\n# plt.title('K-means Clustering Visualization')\n# plt.colorbar(scatter)\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-23T11:57:15.589649Z","iopub.execute_input":"2024-06-23T11:57:15.590171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.cluster import DBSCAN\nfrom sklearn.neighbors import NearestNeighbors\n\n# DBSCAN clustering\n# First, let's find a good eps value using k-distance graph\nneigh = NearestNeighbors(n_neighbors=2)\nnbrs = neigh.fit(X_train)\ndistances, indices = nbrs.kneighbors(X_train)\ndistances = np.sort(distances, axis=0)\ndistances = distances[:,1]\n\nplt.figure(figsize=(10, 8))\nplt.plot(distances)\nplt.title('K-distance Graph')\nplt.xlabel('Data Points sorted by distance')\nplt.ylabel('Epsilon')\nplt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-23T11:10:49.115970Z","iopub.execute_input":"2024-06-23T11:10:49.116685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.cluster import DBSCAN\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\n\n# Sample a subset of your data to reduce memory usage\nsample_size = 50000  # Adjust this based on your available memory\nindices = np.random.choice(X_train.shape[0], sample_size, replace=False)\nX_sample = X_train[indices]\n\n# Choose an epsilon value where the curve starts to elbow\neps = 0.5  # This is an example value, adjust based on your data\nmin_samples = 5  # Adjust this value based on your data\n\n# Perform DBSCAN clustering\ndbscan = DBSCAN(eps=eps, min_samples=min_samples)\ndbscan_labels = dbscan.fit_predict(X_sample)\n\n# Use PCA for visualization (reduce to 2 components)\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X_sample)\n\n# Visualize the clustering\nplt.figure(figsize=(10, 8))\nscatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=dbscan_labels, cmap='viridis')\nplt.title('DBSCAN Clustering Visualization (Sample)')\nplt.colorbar(scatter)\nplt.show()\n\n# Print the number of clusters formed (excluding noise if any)\nn_clusters = len(set(dbscan_labels)) - (1 if -1 in dbscan_labels else 0)\nprint(f\"Number of clusters formed: {n_clusters}\")\n\n# from sklearn.cluster import DBSCAN\n# from sklearn.neighbors import NearestNeighbors\n\n# # Choose an epsilon value where the curve starts to elbow\n# eps = 0.5  # This is an example value, adjust based on the k-distance graph\n# min_samples = 5  # Adjust this value based on your data\n\n# dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n# dbscan_labels = dbscan.fit_predict(X_train)\n\n# # Evaluate the clustering\n# silhouette_avg = silhouette_score(X_train, dbscan_labels)\n# print(f\"The average silhouette score for DBSCAN clustering: {silhouette_avg}\")\n\n# # Visualize the clustering\n# plt.figure(figsize=(10, 8))\n# scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=dbscan_labels, cmap='viridis')\n# plt.title('DBSCAN Clustering Visualization')\n# plt.colorbar(scatter)\n# plt.show()\n\n# # Print the number of clusters formed (excluding noise if any)\n# n_clusters = len(set(dbscan_labels)) - (1 if -1 in dbscan_labels else 0)\n# print(f\"Number of clusters formed: {n_clusters}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-23T11:36:41.155648Z","iopub.execute_input":"2024-06-23T11:36:41.156359Z","iopub.status.idle":"2024-06-23T11:36:55.929711Z","shell.execute_reply.started":"2024-06-23T11:36:41.156320Z","shell.execute_reply":"2024-06-23T11:36:55.928607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.cluster import DBSCAN\nimport matplotlib.pyplot as plt\nfrom sklearn.manifold import TSNE\n\n# Sample a subset of your data\nsample_size = 50000  # Adjust based on your available memory\nindices = np.random.choice(X_train.shape[0], sample_size, replace=False)\nX_sample = X_train[indices]\n\n# Adjust DBSCAN parameters\neps = 2.0  # Increased eps value\nmin_samples = 10  # Increased min_samples\n\n# Perform DBSCAN clustering\ndbscan = DBSCAN(eps=eps, min_samples=min_samples)\ndbscan_labels = dbscan.fit_predict(X_sample)\n\n# Use t-SNE for visualization\ntsne = TSNE(n_components=2, random_state=42)\nX_tsne = tsne.fit_transform(X_sample)\n\n# Visualize the clustering\nplt.figure(figsize=(12, 10))\nscatter = plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=dbscan_labels, cmap='viridis', alpha=0.7)\nplt.colorbar(scatter)\n\n# Highlight noise points\nnoise_mask = dbscan_labels == -1\nplt.scatter(X_tsne[noise_mask, 0], X_tsne[noise_mask, 1], c='gray', alpha=0.1, s=10)\n\nplt.title('DBSCAN Clustering Visualization (t-SNE)')\nplt.xlabel('t-SNE feature 1')\nplt.ylabel('t-SNE feature 2')\nplt.show()\n\n# Print the number of clusters formed (excluding noise)\nn_clusters = len(set(dbscan_labels)) - (1 if -1 in dbscan_labels else 0)\nprint(f\"Number of clusters formed: {n_clusters}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-23T11:45:55.453432Z","iopub.execute_input":"2024-06-23T11:45:55.454287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}